{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "# Starter code\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import isnan, count,lit, when, col, desc, udf, col, sort_array, asc, avg, lag\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import sum as Fsum\n# Create spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Sparkify\") \\\n    .getOrCreate()", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1556980134017_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-31-140.eu-central-1.compute.internal:20888/proxy/application_1556980134017_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-25-105.eu-central-1.compute.internal:8042/node/containerlogs/container_1556980134017_0001_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "# Read in full sparkify dataset\nevent_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\ndf = spark.read.json(event_data)\ndf.head()", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "cfdaf08da83b405795a999fd9def262a"}}, "metadata": {}}, {"output_type": "stream", "text": "Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "In order to automatize a cleaning and transforming process an ETL function was written, which originats from an investigation on \"mini\" version of the dataset. The function below does following:\n1. Cleans dataframe to remove any NaN from \"Gender\" columns (by removing userid '1261737' who is the only user without information about gender)\n2. Prepares timestamps and calculates time differences between user interactions with app\n3. Creates a userid aggregated table with 7 features defined in the study of \"mini\" dataset\n\nAfter application of the ETL function the resulting data is stored in .json file to avoid timeconsuming ETL in the future. As a result a \"df_feature\" table is read from a .json file to accelerate a ML Section."}, {"metadata": {}, "cell_type": "markdown", "source": "## ETL Pipeline"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def ETL(df):\n    # Clean dataset\n    df = df.filter(df.userId != '1261737')\n    \n    # Prepare Timestamps\n    ts_new = udf(lambda x: x / 1000)\n    df = df.withColumn('new_ts', ts_new('ts')).drop('ts')\n    df = df.withColumn('new_reg', ts_new('registration')).drop('registration')\n    \n    # Calculate Time Difference between user interactions with app\n    my_window = Window.partitionBy('userId').orderBy('new_ts')\n\n    df = df.withColumn('prev', lag(df.new_ts).over(my_window))\n    df = df.withColumn('diff_dates', F.when(F.isnull(df.new_ts - df.prev), 0)\n                      .otherwise(df.new_ts - df.prev))\n    \n    #Feature engineering\n    df_features = df.filter(df.page == 'NextSong') \\\n        .groupby('userId') \\\n        .count() \\\n        .withColumnRenamed('count','number_songs')\n\n    df_users_cancelled = df.filter(df.page == 'Cancellation Confirmation') \\\n        .groupby('userId') \\\n        .count() \\\n        .withColumnRenamed('count','Churn') \\\n        .withColumnRenamed('userId','user_canc')\n\n    udf_gender = udf(lambda x: 1 if x == 'M' else 0)\n    df_gender = df.dropDuplicates(['userId']) \\\n        .select(['userId','gender']) \\\n        .withColumnRenamed('userId','user_gender') \\\n        .withColumn('gender',udf_gender('gender'))\n        \n    df_gender = df_gender.withColumn('gender',df_gender.gender.cast(IntegerType()))\n    \n    df_thumbs_down = df.filter(df.page == 'Thumbs Down') \\\n        .groupby('userId') \\\n        .count() \\\n        .withColumnRenamed('count','Thumbs') \\\n        .withColumnRenamed('userId','user_thumbs')\n\n    df_reg = df.groupby('userId') \\\n        .agg({'new_ts':'max','new_reg':'max'}) \\\n        .withColumnRenamed('max(new_ts)','max_ts') \\\n        .withColumnRenamed('max(new_reg)','max_reg') \\\n        .withColumnRenamed('userId','userid_reg_len')\n\n    df_reg = df_reg.withColumn('reg_length',df_reg.max_ts - df_reg.max_reg) \\\n        .select('userid_reg_len','reg_length')\n\n    df_diff_dates_max = df.groupby('userId') \\\n        .agg({'diff_dates':'max'}) \\\n        .withColumnRenamed('max(diff_dates)','diff_dates_max') \\\n        .withColumnRenamed('userId','user_diff_dates_max')\n\n    df_diff_dates_mean = df.groupby('userId') \\\n        .agg({'diff_dates':'avg'}) \\\n        .withColumnRenamed('avg(diff_dates)','diff_dates_mean') \\\n        .withColumnRenamed('userId','user_diff_dates_mean')\n\n    df_diff_dates_week = df.filter(df.diff_dates > 600000) \\\n        .groupby('userId') \\\n        .count() \\\n        .withColumnRenamed('count','diff_dates_session_week') \\\n        .withColumnRenamed('userid','user_diff_dates_week')\n\n    # Joints\n\n    df_features = df_features.join(df_users_cancelled, df_users_cancelled.user_canc == df_features.userId, how = 'left') \\\n        .drop(df_users_cancelled.user_canc)\n    df_features = df_features.join(df_gender, df_gender.user_gender == df_features.userId, how = 'left') \\\n        .drop(df_gender.user_gender)\n    df_features = df_features.join(df_thumbs_down, df_thumbs_down.user_thumbs == df_features.userId, how = 'left') \\\n        .drop(df_thumbs_down.user_thumbs)\n    df_features = df_features.join(df_reg, df_reg.userid_reg_len == df_features.userId, how = 'left') \\\n        .drop(df_reg.userid_reg_len)\n    df_features = df_features.join(df_diff_dates_max, df_diff_dates_max.user_diff_dates_max == df_features.userId, how = 'left') \\\n        .drop(df_diff_dates_max.user_diff_dates_max)\n    df_features = df_features.join(df_diff_dates_mean, df_diff_dates_mean.user_diff_dates_mean == df_features.userId, how = 'left') \\\n        .drop(df_diff_dates_mean.user_diff_dates_mean)\n    df_features = df_features.join(df_diff_dates_week, df_diff_dates_week.user_diff_dates_week == df_features.userId, how = 'left') \\\n        .drop(df_diff_dates_week.user_diff_dates_week)\n\n    df_features = df_features.fillna(0, subset=['Churn','Thumbs','diff_dates_session_week'])\n\n    df_features = df_features.withColumn('Thumbs_Down', F.expr('Thumbs / number_songs')).drop('Thumbs')\n    \n    return df_features", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "512df9e59cf2450dac89810aa168cd45"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_features = ETL(df)", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a4da0bd69a45492db186dc57e76725be"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "path_wr = 's3n://vk1009bucket1/Spark_try1/df_features.json'\ndf_features.write.mode('append').json(path_wr)", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "35c9cd5e27574627b55b33c3edafcf70"}}, "metadata": {}}, {"output_type": "stream", "text": "----------------------------------------\nException happened during processing of request from ('127.0.0.1', 42976)\n----------------------------------------\nTraceback (most recent call last):\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 293, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 321, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 334, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 655, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()", "name": "stdout"}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "path_wr = 's3n://vk1009bucket1/Spark_try1/df_features.json'\ndf_features = spark.read.json(path_wr)", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "54f75af3081b48638cfce3ce5ad0fa84"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_features.head()", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "dd68da764a1d47b28f772e0aa4ca16a8"}}, "metadata": {}}, {"output_type": "stream", "text": "Row(Churn=1, Thumbs_Down=0.016736401673640166, diff_dates_max=1686725.0, diff_dates_mean=6337.923076923077, diff_dates_session_week=1, gender=0, number_songs=239, reg_length=14986090.0, userId=u'1000353')", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Machine Learning"}, {"metadata": {}, "cell_type": "markdown", "source": "### Prepare for ML"}, {"metadata": {}, "cell_type": "markdown", "source": "##### Load Libraries"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.feature import RegexTokenizer, VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier, LogisticRegression, GBTClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "430a4b268f5642a3944a49052cfe4f38"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Data Transformation / TrainTest Split"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Define columns to use\nX = df_features.drop('userid')\nX_cols = X.schema.names\nX_cols.remove('Churn')\n\n# Vector Assembler\nassembler = VectorAssembler(inputCols=X_cols, outputCol='features_vec')\nX = assembler.transform(X)\n\n# Standard Scaller\nscaler = StandardScaler(inputCol='features_vec', outputCol='sc_features',\n                        withStd=True, withMean=False)\n\nScalerModel = scaler.fit(X)\n\nX = ScalerModel.transform(X)\n\n# Train Test Split\n(trainingData, testData) = X.randomSplit([0.7, 0.3])", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "62ad0af0e0714727a210415932e5b0f3"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Search for Best ML Classifier"}, {"metadata": {}, "cell_type": "markdown", "source": "##### Logistic Regression"}, {"metadata": {"scrolled": false, "trusted": true}, "cell_type": "code", "source": "lr = LogisticRegression(labelCol=\"Churn\", featuresCol=\"sc_features\")\n\nparamGrid_lr = ParamGridBuilder() \\\n    .addGrid(lr.maxIter,[5, 10, 20]) \\\n    .addGrid(lr.regParam,[0, 0.1, 1, 10]) \\\n    .build()\n\n\ncrossval_lr = CrossValidator(estimator=lr,\n                          estimatorParamMaps=paramGrid_lr,\n                          evaluator=MulticlassClassificationEvaluator(labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\"),\n                          numFolds=3)\n\nmodel_lr = crossval_lr.fit(trainingData)\n\npred_lr = model_lr.transform(testData)\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluator.evaluate(pred_lr)\nprint('The f1 score achieved using Logistic Regression after Hyperparameter Tuning is {}'.format(round(f1,2)))", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2178903decfc43408e00bf74d30a05ce"}}, "metadata": {}}, {"output_type": "stream", "text": "The f1 score achieved using Logistic Regression after Hyperparameter Tuning is 0.82", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Random Forest"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rf = RandomForestClassifier(labelCol=\"Churn\", featuresCol=\"sc_features\")\n\nparamGrid_rf = ParamGridBuilder() \\\n    .addGrid(rf.numTrees,[1, 10, 20]) \\\n    .addGrid(rf.maxDepth,[2, 5, 10]) \\\n    .build()\n\n\ncrossval_rf = CrossValidator(estimator=rf,\n                          estimatorParamMaps=paramGrid_rf,\n                          evaluator=MulticlassClassificationEvaluator(labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\"),\n                          numFolds=3)\n\nmodel_rf = crossval_rf.fit(trainingData)\n\npred_rf = model_rf.transform(testData)\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluator.evaluate(pred_rf)\nprint('The f1 score achieved using Random Forest Classifier after Hyperparameter Tuning is {}'.format(round(f1,2)))", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "69c90e368a7b475286bbac3b724f831a"}}, "metadata": {}}, {"output_type": "stream", "text": "The f1 score achieved using Random Forest Classifier after Hyperparameter Tuning is 0.86", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### GBT Classifier"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "gbt = GBTClassifier(labelCol=\"Churn\", featuresCol=\"sc_features\")\n\nparamGrid_gbt = ParamGridBuilder() \\\n    .addGrid(gbt.maxIter,[5, 15]) \\\n    .addGrid(gbt.maxDepth,[2, 4]) \\\n    .build()\n\n\ncrossval_gbt = CrossValidator(estimator=gbt,\n                          estimatorParamMaps=paramGrid_gbt,\n                          evaluator=MulticlassClassificationEvaluator(labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\"),\n                          numFolds=3)\n\nmodel_gbt = crossval_gbt.fit(trainingData)\n\npred_gbt = model_gbt.transform(testData)\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Churn\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluator.evaluate(pred_gbt)\nprint('The f1 score achieved using GBT Classifier after Hyperparameter Tuning is {}'.format(round(f1,2)))", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "The f1 score achieved using GBT Classifier after Hyperparameter Tuning is 0.86", "name": "stdout"}, {"output_type": "stream", "text": "Exception in thread cell_monitor-25:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 7076\n\nException in thread cell_monitor-26:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 7599\n\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Conclusion"}, {"metadata": {}, "cell_type": "markdown", "source": "In order to choose the best ML Classification alghorithm 3 approached were tested: Logistic Regression, Random Forest Classifier, GBT Classifier. Each alghorthm was tuned using hyperparameter tuning of at least two parameters.F1 Score was used as an evaluation metric.\n\nResult:\n1. Random Forest (F1 = 0.86)\n2. GBT Classifier (F1 = 0.86)\n3. Logistic Regression (F1 = 0.82)\n\nAs expected ensemble methods showed a way better F1 Score in comparison with Logistic Regression. However, the difference between both ensemble alghorithms is tiny. So in the next part both alghorithms are investigated for feature importance."}, {"metadata": {}, "cell_type": "markdown", "source": "### Get feature Importance from RF Classifier"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "best_model_rf = model_rf.bestModel\n\nbest_num_trees = best_model_rf._java_obj.getNumTrees()\nbest_max_depth = best_model_rf._java_obj.getMaxDepth()\n\nrf_best = RandomForestClassifier(labelCol=\"Churn\", featuresCol=\"sc_features\", numTrees=best_num_trees, maxDepth=best_max_depth)\n\nmodel_fin = rf_best.fit(trainingData)", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "model_fin.featureImportances", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "SparseVector(7, {0: 0.0836, 1: 0.2483, 2: 0.1167, 3: 0.1083, 4: 0.0129, 5: 0.177, 6: 0.2532})", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "X_cols", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "['Thumbs_Down', 'diff_dates_max', 'diff_dates_mean', 'diff_dates_session_week', 'gender', 'number_songs', 'reg_length']", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Get feature Importance from GBT Classifier"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "best_model_gbt = model_gbt.bestModel\n\nbest_max_iter = best_model_gbt._java_obj.getMaxIter()\nbest_max_depth = best_model_gbt._java_obj.getMaxDepth()\n\ngbt_best = GBTClassifier(labelCol=\"Churn\", featuresCol=\"sc_features\", maxIter = best_max_iter, maxDepth=best_max_depth)\n\nmodel_fin_gbt = gbt_best.fit(trainingData)", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "98a4d5a8386d401e939bc9a2fca3ba3e"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "model_fin_gbt.featureImportances", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "349f6a1114024b1cac549c7c0b06d6df"}}, "metadata": {}}, {"output_type": "stream", "text": "SparseVector(7, {0: 0.1041, 1: 0.2062, 2: 0.2697, 3: 0.0375, 4: 0.0011, 5: 0.2676, 6: 0.1138})", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "X_cols", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a2b0be698c504348b691403f8cfae8fe"}}, "metadata": {}}, {"output_type": "stream", "text": "['Thumbs_Down', 'diff_dates_max', 'diff_dates_mean', 'diff_dates_session_week', 'gender', 'number_songs', 'reg_length']", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##### Conclusion"}, {"metadata": {}, "cell_type": "markdown", "source": "In order to investigate the feature importnaces the best sets of parameters from both RF and GBT models were used for the final versions of the models. \n\nResult\n\nRandom Forest Classifier's top features:\n1. 'reg_length' 0.253\n2. 'diff_dates_max' 0.248\n3. 'number_songs' 0.177\n\nGBT Classifier's top features:\n1. 'diff_dates_mean' 0.27\n2. 'number_songs' 0.268\n3. 'diff_dates_max' 0.206\n\nSo, both classifiers agreed that the amount of songs user listened as well as the time difference between sessions are the most influential parameters for user to stay or cancel the subsription."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}